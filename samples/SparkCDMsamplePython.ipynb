{"cells":[{"cell_type":"code","source":["appid = \"<appId>\"\nappkey = \"<appKey>\"\ntenantid = \"<tenantId>\"\n\ncontainer = \"<demoContainerName>\"\nstorageAccountName = \"<storageAccount>.dfs.core.windows.net\""],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# Implicit write case\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions, Row\nfrom decimal import Decimal\nfrom datetime import datetime\n\n# Write a CDM entity with Parquet data files, entity definition is derived from the dataframe schema\nd = datetime.strptime(\"2015-03-31\", '%Y-%m-%d')\nts = datetime.now()\ndata = [\n  [\"a\", 1, True, 12.34, 6, d, ts, Decimal(1.4337879), Decimal(999.00), Decimal(18.8)],\n  [\"b\", 1, True, 12.34, 6, d, ts, Decimal(1.4337879), Decimal(999.00), Decimal(18.8)]\n]\n\nschema = (StructType()\n  .add(StructField(\"name\", StringType(), True))\n  .add(StructField(\"id\", IntegerType(), True))\n  .add(StructField(\"flag\", BooleanType(), True))\n  .add(StructField(\"salary\", DoubleType(), True))\n  .add(StructField(\"phone\", LongType(), True))\n  .add(StructField(\"dob\", DateType(), True))\n  .add(StructField(\"time\", TimestampType(), True))\n  .add(StructField(\"decimal1\", DecimalType(15, 3), True))\n  .add(StructField(\"decimal2\", DecimalType(38, 7), True))\n  .add(StructField(\"decimal3\", DecimalType(5, 2), True))\n)\n\ndf = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)\n\n# Creates the CDM manifest and adds the entity to it with gzip'd parquet partitions\n# with both physical and logical entity definitions \n(df.write.format(\"com.microsoft.cdm\")\n  .option(\"storage\", storageAccountName)\n  .option(\"container\", container)\n  .option(\"manifest\", \"/implicitTest/default.manifest.cdm.json\")\n  .option(\"entity\", \"TestEntity\")\n  .option(\"format\", \"parquet\")\n  .option(\"compression\", \"gzip\")\n  .option(\"appId\", appid)\n  .option(\"appKey\", appkey)\n  .option(\"tenantId\", tenantid)\n  .save())\n\n# Append the same dataframe content to the entity in the default CSV format\n(df.write.format(\"com.microsoft.cdm\")\n  .option(\"storage\", storageAccountName)\n  .option(\"container\", container)\n  .option(\"manifest\", \"/implicitTest/default.manifest.cdm.json\")\n  .option(\"entity\", \"TestEntity1\")\n  .option(\"appId\", appid)\n  .option(\"appKey\", appkey)\n  .option(\"tenantId\", tenantid)\n  .mode(\"append\")\n  .save())\n\nreadDf = (spark.read.format(\"com.microsoft.cdm\")\n  .option(\"storage\", storageAccountName)\n  .option(\"container\", container)\n  .option(\"manifest\", \"/implicitTest/default.manifest.cdm.json\")\n  .option(\"entity\", \"TestEntity\")\n  .option(\"appId\", appid)\n  .option(\"appKey\", appkey)\n  .option(\"tenantId\", tenantid)\n  .load())\n\nreadDf.select(\"*\").show()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Explicit write, creating an entity in a CDM folder based on a pre-defined model \n\n# Case 1: Using an entity definition defined in the CDM Github repo\n\ndata = [\n  [\"1\", \"2\", \"3\", 4],\n  [\"4\", \"5\", \"6\", 8],\n  [\"7\", \"8\", \"9\", 4],\n  [\"10\", \"11\", \"12\", 8],\n  [\"13\", \"14\", \"15\", 4]\n]\n\nschema = (StructType()\n  .add(StructField(\"teamMembershipId\", StringType(), True))\n  .add(StructField(\"systemUserId\", StringType(), True))\n  .add(StructField(\"teamId\", StringType(), True))\n  .add(StructField(\"versionNumber\", LongType(), True))\n)\n\ndf = spark.createDataFrame(spark.sparkContext.parallelize(data,1), schema)\n          \n(df.write.format(\"com.microsoft.cdm\")\n  .option(\"storage\", storageAccountName)\n  .option(\"container\", container)\n  .option(\"manifest\", \"explicitTest/root.manifest.cdm.json\")\n  .option(\"entity\", \"TeamMembership\")\n  .option(\"entityDefinition\", \"core/applicationCommon/TeamMembership.cdm.json/TeamMembership\")\n  .option(\"useCdmGithubModelRoot\", True)  # sets the model root to the CDM GitHub schema documents folder\n  .option(\"useSubManifest\", True)\n  .option(\"appId\", appid)\n  .option(\"appKey\", appkey)\n  .option(\"tenantId\", tenantid)\n  .mode(\"overwrite\")\n  .save())\n\nreadDf = (spark.read.format(\"com.microsoft.cdm\")\n  .option(\"storage\", storageAccountName)\n  .option(\"container\", container)\n  .option(\"manifest\", \"/explicitTest/root.manifest.cdm.json\")\n  .option(\"entity\", \"TeamMembership\")\n  .option(\"useCDMGithub\", True) # sets the modelroot alias to the CDM GitHub schema documents folder\n  .option(\"appId\", appid)\n  .option(\"appKey\", appkey)\n  .option(\"tenantId\", tenantid)\n  .load())\n          \nreadDf.select(\"*\").show()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Explicit write, creating an entity in a CDM folder based on a pre-defined model \n\n# Case 2: Using an entity definition defined in a CDM model stored in ADLS\n\n# UPLOAD CDM FILES FIRST\n# To run this example, first create a /Models/Contacts folder to your demo container in ADLS gen2,\n# then upload the provided Contacts.manifest.cdm.json, Person.cdm.json, Entity.cdm.json files\n\nbirthdate = datetime.strptime(\"1991-03-31\", '%Y-%m-%d')\nnow = datetime.now()\ndata2 = [\n  [1,now,\"Donna\",\"Carreras\",birthdate],\n  [2,now,\"Keith\",\"Harris\",birthdate],\n  [2,now,\"Carla\",\"McGee\",birthdate]\n]\n\nschema2 = (StructType()\n  .add(StructField(\"identifier\", IntegerType()))\n  .add(StructField(\"createdTime\", TimestampType()))\n  .add(StructField(\"firstName\", StringType()))\n  .add(StructField(\"lastName\", StringType()))\n  .add(StructField(\"birthDate\", DateType())))\n\n# Create the dataframe that matches the CDM definition of the entity, Person\ndf2 = spark.createDataFrame(spark.sparkContext.parallelize(data2, 1), schema2)\n(df2.write.format(\"com.microsoft.cdm\")\n  .option(\"storage\", storageAccountName)\n  .option(\"container\", container)\n  .option(\"manifest\", \"/Data/Contacts/root.manifest.cdm.json\")\n  .option(\"entity\", \"Person\")\n  .option(\"entityDefinitionContainer\", container)\n  .option(\"entityDefinitionModelRoot\", \"Models\") \n  .option(\"entityDefinition\", \"/Contacts/Person.cdm.json/Person\")   \n  .option(\"appId\", appid).option(\"appKey\", appkey).option(\"tenantId\", tenantid)\n  .mode(\"overwrite\")\n  .save())\n\nreadDf2 = (spark.read.format(\"com.microsoft.cdm\")\n  .option(\"storage\", storageAccountName)\n  .option(\"container\", container)\n  .option(\"manifest\", \"/Data/Contacts/root.manifest.cdm.json\")\n  .option(\"entity\", \"Person\")\n  .option(\"entityDefinitionContainer\", container)\n  .option(\"entityDefinitionModelRoot\", \"Models\")\n  .option(\"appId\", appid).option(\"appKey\", appkey).option(\"tenantId\", tenantid)\n  .load())\n\nreadDf2.select(\"*\").show()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql import functions, Row\nfrom decimal import Decimal\nfrom datetime import datetime\n\nbirthdate = datetime.strptime(\"1991-03-31\", '%Y-%m-%d')\nnow = datetime.now()\n\ndata2 = [\n  [13, [\"Donna Carreras\", True, 12.34, 63232, birthdate, Decimal(22.7), now, [95110, [\"Bose street\", 321], [['bieber1', 1], ['bieber2', 2]] ]]],\n  [24, [\"Keith Harris\", True, 12.34, 63234, birthdate, Decimal(22.7), now, [95110, [\"Estancia Dr\", 185], [['baby1', 3], ['baby2', 34], ['baby3', 5], ['baby4', 6]] ]]]\n]\n\nstreetSchema = [StructField(\"streetName\", StringType(), True),\n               StructField(\"streetNumber\", IntegerType(), True)]\n\nsongSchema = [StructField(\"name\", StringType(), True),\n               StructField(\"number\", IntegerType(), True)]\n\naddressSchema = [StructField(\"zipcode\", StringType(), True),\n                StructField(\"street\", StructType(streetSchema), True),\n                StructField(\"songs\", ArrayType(StructType(songSchema)), True)]\n\ndetailSchema = [StructField(\"name\", StringType(), True),\n                StructField(\"USCitizen\", BooleanType(), True),\n                StructField(\"salary\", DoubleType(), True),\n                StructField(\"phone\", LongType(), True),\n                StructField(\"birthDate\", DateType(), True),\n                StructField(\"bodyMassIndex\", DecimalType(5, 2), True),\n                StructField(\"createdTime\", TimestampType(), True),\n                StructField(\"address\", StructType(addressSchema), True)]\n\nschema = [StructField(\"id\", IntegerType(), True),\n          StructField(\"details\", StructType(detailSchema), True)]\n\nschema2 = StructType(schema)\n\n# Create the dataframe\ndf2 = spark.createDataFrame(spark.sparkContext.parallelize(data2), schema2)\n\n# Implicit write\n(df2.write.format(\"com.microsoft.cdm\")\n  .option(\"storage\", storageAccountName)\n  .option(\"container\", container)\n  .option(\"manifest\", \"/nestedImplicit/default.manifest.cdm.json\")\n  .option(\"entity\", \"NestedExampleImplicit\")\n  .option(\"useCdmGithubModelRoot\", True)\n  .option(\"format\", \"parquet\")\n  .option(\"appId\", appid).option(\"appKey\", appkey).option(\"tenantId\", tenantid)\n  .save())\n\n#Explicit write\n\n#To run this example, first create a /Models/Contacts folder to your demo container in ADLS gen2,\n#then upload the provided NestedExample.cdm.json file\n(df2.write.format(\"com.microsoft.cdm\")\n  .option(\"storage\", storageAccountName)\n  .option(\"container\", container)\n  .option(\"manifest\", \"/nestedExplicit/default.manifest.cdm.json\")\n  .option(\"entity\", \"NestedExampleExplicit\")\n  .option(\"entityDefinition\", \"/Contacts/NestedExample.cdm.json/NestedExample\")\n  .option(\"entityDefinitionModelRoot\", \"Models\")\n  .option(\"entityDefinitionContainer\", container)\n  .option(\"format\", \"parquet\")\n  .option(\"appId\", appid).option(\"appKey\", appkey).option(\"tenantId\", tenantid)\n  .save())\n\nreadImplicit = (spark.read.format(\"com.microsoft.cdm\")\n  .option(\"storage\", storageAccountName)\n  .option(\"container\", container)\n  .option(\"manifest\", \"/nestedImplicit/default.manifest.cdm.json\")\n  .option(\"entity\", \"NestedExampleImplicit\")\n  .option(\"appId\", appid).option(\"appKey\", appkey).option(\"tenantId\", tenantid)\n  .load())\n\nreadExplicit = (spark.read.format(\"com.microsoft.cdm\")\n  .option(\"storage\", storageAccountName)\n  .option(\"container\", container)\n  .option(\"manifest\", \"/nestedExplicit/default.manifest.cdm.json\")\n  .option(\"entity\", \"NestedExampleExplicit\")\n  .option(\"appId\", appid).option(\"appKey\", appkey).option(\"tenantId\", tenantid)\n  .load())\n\ndf2.select(\"*\").show(truncate = False)\nreadImplicit.select(\"*\").show(truncate = False)\nreadExplicit.select(\"*\").show(truncate = False)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\nid |details                                                                                                                                                          |\n+---+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n13 |[Donna Carreras, true, 12.34, 63232, 1991-03-31, 22.70, 2020-06-08 20:34:46.232167, [95110, [Bose street, 321], [[bieber1, 1], [bieber2, 2]]]]                   |\n24 |[Keith Harris, true, 12.34, 63234, 1991-03-31, 22.70, 2020-06-08 20:34:46.232167, [95110, [Estancia Dr, 185], [[baby1, 3], [baby2, 34], [baby3, 5], [baby4, 6]]]]|\n+---+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n+---+----------------------------------------------------------------------------------------------------------------------------------------------------------+\nid |details                                                                                                                                                   |\n+---+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n13 |[Donna Carreras, true, 12.34, 63232, 1991-03-31, 22.70, 2020-06-08 20:34:46, [95110, [Bose street, 321], [[bieber1, 1], [bieber2, 2]]]]                   |\n24 |[Keith Harris, true, 12.34, 63234, 1991-03-31, 22.70, 2020-06-08 20:34:46, [95110, [Estancia Dr, 185], [[baby1, 3], [baby2, 34], [baby3, 5], [baby4, 6]]]]|\n+---+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n+---+----------------------------------------------------------------------------------------------------------------------------------------------------------+\nid |details                                                                                                                                                   |\n+---+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n13 |[Donna Carreras, true, 12.34, 63232, 1991-03-31, 22.70, 2020-06-08 20:34:46, [95110, [Bose street, 321], [[bieber1, 1], [bieber2, 2]]]]                   |\n24 |[Keith Harris, true, 12.34, 63234, 1991-03-31, 22.70, 2020-06-08 20:34:46, [95110, [Estancia Dr, 185], [[baby1, 3], [baby2, 34], [baby3, 5], [baby4, 6]]]]|\n+---+----------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":5}],"metadata":{"name":"SparkCDMDemoPython","notebookId":2733371104003271},"nbformat":4,"nbformat_minor":0}
