{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Specifying appid, appkey and tenanid is optional in spark-cdm-connector-assembly-0.16.jar with Premium Databricks Cluster and Synapse\n",
        "appid = \"<appId>\"\n",
        "appkey = \"<appKey>\"\n",
        "tenantid = \"<tenantId>\"\n",
        "\n",
        "storageAccountName = \"<storageAccount>.dfs.core.windows.net\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "fef08891-af87-48f9-adf2-e24588f4f0b5",
          "showTitle": false,
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implicit write case\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions, Row\n",
        "from decimal import Decimal\n",
        "from datetime import datetime\n",
        "\n",
        "# Write a CDM entity with Parquet data files, entity definition is derived from the dataframe schema\n",
        "d = datetime.strptime(\"2015-03-31\", '%Y-%m-%d')\n",
        "ts = datetime.now()\n",
        "data = [\n",
        "  [\"a\", 1, True, 12.34, 6, d, ts, Decimal(1.4337879), Decimal(999.00), Decimal(18.8)],\n",
        "  [\"b\", 1, True, 12.34, 6, d, ts, Decimal(1.4337879), Decimal(999.00), Decimal(18.8)]\n",
        "]\n",
        "\n",
        "schema = (StructType()\n",
        "  .add(StructField(\"name\", StringType(), True))\n",
        "  .add(StructField(\"id\", IntegerType(), True))\n",
        "  .add(StructField(\"flag\", BooleanType(), True))\n",
        "  .add(StructField(\"salary\", DoubleType(), True))\n",
        "  .add(StructField(\"phone\", LongType(), True))\n",
        "  .add(StructField(\"dob\", DateType(), True))\n",
        "  .add(StructField(\"time\", TimestampType(), True))\n",
        "  .add(StructField(\"decimal1\", DecimalType(15, 3), True))\n",
        "  .add(StructField(\"decimal2\", DecimalType(38, 7), True))\n",
        "  .add(StructField(\"decimal3\", DecimalType(5, 2), True))\n",
        ")\n",
        "\n",
        "df = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)\n",
        "\n",
        "# Creates the CDM manifest and adds the entity to it with gzip'd parquet partitions\n",
        "# with both physical and logical entity definitions \n",
        "(df.write.format(\"com.microsoft.cdm\")\n",
        "  .option(\"storage\", storageAccountName)\n",
        "  .option(\"manifestPath\", container + \"/implicitTest/default.manifest.cdm.json\")\n",
        "  .option(\"entity\", \"TestEntity\")\n",
        "  .option(\"format\", \"parquet\")\n",
        "  .option(\"compression\", \"gzip\")\n",
        "  .save())\n",
        "\n",
        "# Append the same dataframe content to the entity in the default CSV format\n",
        "(df.write.format(\"com.microsoft.cdm\")\n",
        "  .option(\"storage\", storageAccountName)\n",
        "  .option(\"manifestPath\", container + \"/implicitTest/default.manifest.cdm.json\")\n",
        "  .option(\"entity\", \"TestEntity\")\n",
        "  .mode(\"append\")\n",
        "  .save())\n",
        "\n",
        "readDf = (spark.read.format(\"com.microsoft.cdm\")\n",
        "  .option(\"storage\", storageAccountName)\n",
        "  .option(\"manifestPath\", container + \"/implicitTest/default.manifest.cdm.json\")\n",
        "  .option(\"entity\", \"TestEntity\")\n",
        "  .load())\n",
        "\n",
        "readDf.select(\"*\").show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "797d97b4-54e3-4f78-8da3-20638d7fb352",
          "showTitle": false,
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explicit write, creating an entity in a CDM folder based on a pre-defined model \n",
        "\n",
        "# Case 1: Using an entity definition defined in the CDM Github repo\n",
        "\n",
        "data = [\n",
        "  [\"1\", \"2\", \"3\", 4],\n",
        "  [\"4\", \"5\", \"6\", 8],\n",
        "  [\"7\", \"8\", \"9\", 4],\n",
        "  [\"10\", \"11\", \"12\", 8],\n",
        "  [\"13\", \"14\", \"15\", 4]\n",
        "]\n",
        "\n",
        "schema = (StructType()\n",
        "  .add(StructField(\"teamMembershipId\", StringType(), True))\n",
        "  .add(StructField(\"systemUserId\", StringType(), True))\n",
        "  .add(StructField(\"teamId\", StringType(), True))\n",
        "  .add(StructField(\"versionNumber\", LongType(), True))\n",
        ")\n",
        "\n",
        "df = spark.createDataFrame(spark.sparkContext.parallelize(data,1), schema)\n",
        "          \n",
        "(df.write.format(\"com.microsoft.cdm\")\n",
        "  .option(\"storage\", storageAccountName)\n",
        "  .option(\"manifestPath\", container + \"/explicitTest/root.manifest.cdm.json\")\n",
        "  .option(\"entity\", \"TeamMembership\")\n",
        "  .option(\"entityDefinitionPath\", \"core/applicationCommon/TeamMembership.cdm.json/TeamMembership\")\n",
        "  .option(\"useCdmStandardModelRoot\", True)  # sets the model root to the CDM CDN schema documents folder\n",
        "  .option(\"useSubManifest\", True)\n",
        "  .save()) # If table already exists, add .mode(\"overwrite\")\n",
        "\n",
        "readDf = (spark.read.format(\"com.microsoft.cdm\")\n",
        "  .option(\"storage\", storageAccountName)\n",
        "  .option(\"manifestPath\", container + \"/explicitTest/root.manifest.cdm.json\")\n",
        "  .option(\"entity\", \"TeamMembership\")\n",
        "  .load())\n",
        "          \n",
        "readDf.select(\"*\").show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "07b34bbb-0ee7-4151-969e-5198d0ad057a",
          "showTitle": false,
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explicit write, creating an entity in a CDM folder based on a pre-defined model \n",
        "\n",
        "# Case 2: Using an entity definition defined in a CDM model stored in ADLS\n",
        "\n",
        "# UPLOAD CDM FILES FIRST\n",
        "# To run this example, first create a /Models/Contacts folder to your demo container in ADLS gen2,\n",
        "# then upload the provided Contacts.manifest.cdm.json, Person.cdm.json, Entity.cdm.json files\n",
        "\n",
        "birthdate = datetime.strptime(\"1991-03-31\", '%Y-%m-%d')\n",
        "now = datetime.now()\n",
        "data2 = [\n",
        "  [1,now,\"Donna\",\"Carreras\",birthdate],\n",
        "  [2,now,\"Keith\",\"Harris\",birthdate],\n",
        "  [2,now,\"Carla\",\"McGee\",birthdate]\n",
        "]\n",
        "\n",
        "schema2 = (StructType()\n",
        "  .add(StructField(\"identifier\", IntegerType()))\n",
        "  .add(StructField(\"createdTime\", TimestampType()))\n",
        "  .add(StructField(\"firstName\", StringType()))\n",
        "  .add(StructField(\"lastName\", StringType()))\n",
        "  .add(StructField(\"birthDate\", DateType())))\n",
        "\n",
        "# Create the dataframe that matches the CDM definition of the entity, Person\n",
        "df2 = spark.createDataFrame(spark.sparkContext.parallelize(data2, 1), schema2)\n",
        "(df2.write.format(\"com.microsoft.cdm\")\n",
        "  .option(\"storage\", storageAccountName)\n",
        "  .option(\"manifestPath\", container + \"/Data/Contacts/root.manifest.cdm.json\")\n",
        "  .option(\"entity\", \"Person\")\n",
        "  .option(\"entityDefinitionModelRoot\", container + \"/Models\") \n",
        "  .option(\"entityDefinitionPath\", \"/Contacts/Person.cdm.json/Person\")\n",
        "  .save()) # If table already exists, add .mode(\"overwrite\")\n",
        "\n",
        "readDf2 = (spark.read.format(\"com.microsoft.cdm\")\n",
        "  .option(\"storage\", storageAccountName)\n",
        "  .option(\"manifestPath\", container + \"/Data/Contacts/root.manifest.cdm.json\")\n",
        "  .option(\"entity\", \"Person\")\n",
        "  .load())\n",
        "\n",
        "readDf2.select(\"*\").show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "630e4726-303e-41c7-9919-b1631e4a9133",
          "showTitle": false,
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Overriding from configPath\n",
        "\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions, Row\n",
        "from decimal import Decimal\n",
        "from datetime import datetime\n",
        "\n",
        "timestamp1 = datetime.now()\n",
        "timestamp2 = datetime.now()\n",
        "cdata = [\n",
        "  [timestamp1, timestamp2, 1, \"A\", Decimal(33.5)],\n",
        "  [timestamp1, timestamp2, 2, \"B\", Decimal(42.1)],\n",
        "  [timestamp1, timestamp2, 3, \"C\", Decimal(7.90)]\n",
        "]\n",
        "    \n",
        "cschema = (StructType()\n",
        "  .add(StructField(\"ValidFrom\", TimestampType()))\n",
        "  .add(StructField(\"ValidTo\", TimestampType()))\n",
        "  .add(StructField(\"CustomerId\", IntegerType()))\n",
        "  .add(StructField(\"CustomerName\", StringType()))\n",
        "  .add(StructField(\"CreditLimit\", DecimalType(18, 2))))\n",
        "\n",
        "# Create the dataframe\n",
        "customerdf = spark.createDataFrame(spark.sparkContext.parallelize(cdata), cschema)\n",
        "\n",
        "(customerdf.write.format(\"com.microsoft.cdm\")\n",
        "  .option(\"storage\", storageAccountName)\n",
        "  .option(\"manifestPath\", outputContainer + \"/customer/default.manifest.cdm.json\")\n",
        "  .option(\"entity\", \"TestEntity\")\n",
        "  .option(\"entityDefinitionPath\", \"Customer.cdm.json/Customer\")  # Customer.cdm.json has an alias - \"core\"\n",
        "  .option(\"entityDefinitionModelRoot\", container + \"Models\")   # fetches config.json from this location and finds definition of \"core\" alias, if configPath option is not present\n",
        "  .option(\"configPath\", \"/config\")  # Add your config.json to override the above definition. This will find config.json in container - \"config\"\n",
        "  .option(\"entityDefinitionStorage\", \"<storage1>.dfs.core.windows.net\") # entityDefinitionModelRoot contains in this storage account\n",
        "  .option(\"format\", \"parquet\")\n",
        "  .save())\n",
        "\n",
        "readDf2 = (spark.read.format(\"com.microsoft.cdm\")\n",
        "  .option(\"storage\", storageAccountName)\n",
        "  .option(\"manifestPath\", outputContainer + \"/customer/default.manifest.cdm.json\")\n",
        "  .option(\"entity\", \"TestEntity\")\n",
        "  .load())\n",
        "\n",
        "readDf2.select(\"*\").show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "e836ce32-507b-406c-a4e9-58a05c8d8670",
          "showTitle": false,
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions, Row\n",
        "from decimal import Decimal\n",
        "from datetime import datetime\n",
        "\n",
        "birthdate = datetime.strptime(\"1991-03-31\", '%Y-%m-%d')\n",
        "now = datetime.now()\n",
        "\n",
        "data2 = [\n",
        "  [13, [\"Donna Carreras\", True, 12.34, 63232, birthdate, Decimal(22.7), now, [95110, [\"Bose street\", 321], [['bieber1', 1], ['bieber2', 2]] ]]],\n",
        "  [24, [\"Keith Harris\", True, 12.34, 63234, birthdate, Decimal(22.7), now, [95110, [\"Estancia Dr\", 185], [['baby1', 3], ['baby2', 34], ['baby3', 5], ['baby4', 6]] ]]]\n",
        "]\n",
        "\n",
        "streetSchema = [StructField(\"streetName\", StringType(), True),\n",
        "               StructField(\"streetNumber\", IntegerType(), True)]\n",
        "\n",
        "songSchema = [StructField(\"name\", StringType(), True),\n",
        "               StructField(\"number\", IntegerType(), True)]\n",
        "\n",
        "addressSchema = [StructField(\"zipcode\", StringType(), True),\n",
        "                StructField(\"street\", StructType(streetSchema), True),\n",
        "                StructField(\"songs\", ArrayType(StructType(songSchema)), True)]\n",
        "\n",
        "detailSchema = [StructField(\"name\", StringType(), True),\n",
        "                StructField(\"USCitizen\", BooleanType(), True),\n",
        "                StructField(\"salary\", DoubleType(), True),\n",
        "                StructField(\"phone\", LongType(), True),\n",
        "                StructField(\"birthDate\", DateType(), True),\n",
        "                StructField(\"bodyMassIndex\", DecimalType(5, 2), True),\n",
        "                StructField(\"createdTime\", TimestampType(), True),\n",
        "                StructField(\"address\", StructType(addressSchema), True)]\n",
        "\n",
        "schema = [StructField(\"id\", IntegerType(), True),\n",
        "          StructField(\"details\", StructType(detailSchema), True)]\n",
        "\n",
        "schema2 = StructType(schema)\n",
        "\n",
        "# Create the dataframe\n",
        "df2 = spark.createDataFrame(spark.sparkContext.parallelize(data2), schema2)\n",
        "\n",
        "# Implicit write\n",
        "(df2.write.format(\"com.microsoft.cdm\")\n",
        "  .option(\"storage\", storageAccountName)\n",
        "  .option(\"manifestPath\", container + \"/nestedImplicit/default.manifest.cdm.json\")\n",
        "  .option(\"entity\", \"NestedExampleImplicit\")\n",
        "  .option(\"format\", \"parquet\")\n",
        "  .save())\n",
        "\n",
        "#Explicit write\n",
        "\n",
        "#To run this example, first create a /Models/Contacts folder to your demo container in ADLS gen2,\n",
        "#then upload the provided NestedExample.cdm.json file\n",
        "(df2.write.format(\"com.microsoft.cdm\")\n",
        "  .option(\"storage\", storageAccountName)\n",
        "  .option(\"manifestPath\", container + \"/nestedExplicit/default.manifest.cdm.json\")\n",
        "  .option(\"entity\", \"NestedExampleExplicit\")\n",
        "  .option(\"entityDefinitionPath\", \"/Contacts/NestedExample.cdm.json/NestedExample\")\n",
        "  .option(\"entityDefinitionModelRoot\", container + \"/Models\")\n",
        "  .option(\"format\", \"parquet\")\n",
        "  .save())\n",
        "\n",
        "readImplicit = (spark.read.format(\"com.microsoft.cdm\")\n",
        "  .option(\"storage\", storageAccountName)\n",
        "  .option(\"manifestPath\", container + \"/nestedImplicit/default.manifest.cdm.json\")\n",
        "  .option(\"entity\", \"NestedExampleImplicit\")\n",
        "  .load())\n",
        "\n",
        "readExplicit = (spark.read.format(\"com.microsoft.cdm\")\n",
        "  .option(\"storage\", storageAccountName)\n",
        "  .option(\"manifestPath\", container + \"/nestedExplicit/default.manifest.cdm.json\")\n",
        "  .option(\"entity\", \"NestedExampleExplicit\")\n",
        "  .load())\n",
        "\n",
        "df2.select(\"*\").show(truncate = False)\n",
        "readImplicit.select(\"*\").show(truncate = False)\n",
        "readExplicit.select(\"*\").show(truncate = False)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "abdb37e8-b4c8-4acc-b5d5-9c600c0d2445",
          "showTitle": false,
          "title": ""
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
