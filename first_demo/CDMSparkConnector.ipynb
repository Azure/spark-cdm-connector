{"nbformat_minor": 4, "cells": [{"source": "## The Line below should exists as a cell by itself", "cell_type": "markdown", "metadata": {"cell_status": {"execute_time": {"duration": 2.467041015625, "end_time": 1580885349041.31}}}}, {"execution_count": null, "cell_type": "code", "source": "%%configure -f\n{ \"jars\": [\"wasbs://jars@tcbstoragecdm.blob.core.windows.net/spark-cdm-connector-assembly-0.3.jar\"]}", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 17.721923828125, "end_time": 1581041399081.193}}, "collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "val appid=\"c33b62ef-558c-4046-ac45-6a7c3a9a4745\"\nval appkey=\"@=D:8H9JFqn@SmAuwn3eZwy6bjAc90d1\"\nval tenantid=\"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n\n\nval storage = \"tcbstoragecdm.dfs.core.windows.net\"\nval outputContainer=\"/output\"\nval entity = \"TestEntity\"", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 1267.612060546875, "end_time": 1581041436432.229}}, "collapsed": false}}, {"source": "## Simple Test to demonstrate parquet data writes and read with CDM metadata", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import org.apache.spark.sql.types._\nimport org.apache.spark.sql._\n\nval data = Seq(\n    Row(\"tim\", 1),\n    Row(\"brad\", 10)\n)\n\nval schema = (new StructType()\n    .add(StructField(\"name\", StringType, true))\n    .add(StructField(\"id\", IntegerType, true)))\n\nval df = spark.createDataFrame(spark.sparkContext.parallelize(data),schema)\n\n//Create a new manifest and add the entity to it\n(df.write.format(\"com.microsoft.cdm\")\n    .option(\"storage\", storage)\n    .option(\"container\", outputContainer)\n    .option(\"manifest\", \"default.manifest.cdm.json\")\n    .option(\"entity\", entity)\n    .option(\"format\", \"parquet\")\n    .option(\"appId\", appid)\n    .option(\"appKey\", appkey)\n    .option(\"tenantId\", tenantid)\n    .save())\n\nval partitions = df.rdd.getNumPartitions\n\nval readDf = (spark.read.format(\"com.microsoft.cdm\")\n    .option(\"storage\", storage)\n    .option(\"container\", outputContainer)\n    .option(\"manifest\", \"default.manifest.cdm.json\")\n    .option(\"entity\", entity)\n    .option(\"appId\", appid)\n    .option(\"appKey\", appkey)\n    .option(\"tenantId\", tenantid)\n    .load())\n\ndf.select(\"*\").show(2)\nval res = df.select(\"name\").collect()(0)\nassert(df.select(\"name\").collect()(0).getString(0) == \"tim\")\nassert(df.select(\"id\").collect()(1).getInt(0) == 10)\n", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 11330.114013671875, "end_time": 1581040183087.023}}, "collapsed": false}}, {"source": "## Clean-up the contents from ADLS", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import com.microsoft.cdm.utils.{AADProvider,ADLGen2Provider}\nimport java.io.StringWriter\nimport org.apache.commons.io.IOUtils\n\nval adlProvider = new ADLGen2Provider(new AADProvider(appid, appkey, tenantid))\nadlProvider.deleteFile(\"https://\" + storage + outputContainer + \"/\" + entity +\".cdm.json\")\nadlProvider.deleteFile(\"https://\" + storage + outputContainer + \"/default.manifest.cdm.json\")\nadlProvider.deleteFile(\"https://\" + storage + outputContainer + \"/config.json\")\nfor (i <-0 until partitions) {\n    adlProvider.deleteFile(\"https://\" + storage + outputContainer + \"/\" + entity + \"/pdata\" + i + \".parquet\")\n}\n\n", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 7339.068115234375, "end_time": 1580944398258.816}}, "collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 751.236083984375, "end_time": 1580891457841.604}}, "collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}}}