# spark-cdm-connector

A limited preview release of a connector, for use with **Azure Databricks** and **Apache Spark for Azure Synapse**, that allows Spark dataframes to read and write entities in a CDM folder.  For more information and a list of known issues, please see [Using the Spark CDM Connector](documentation/overview.md).  

**The Spark CDM Connector is currently in an early limited preview and may change without notice.  It is not recommended or supported for use in production applications.**

To get started, please see: [Using the Spark CDM Connector](documentation/overview.md).

To report problems, ask questions or provide feedback, please send mail to asksparkcdm@microsoft.com.

For more information about CDM see: https://docs.microsoft.com/en-us/common-data-model/ 

# Maven
The library is also available via Maven: https://mvnrepository.com/artifact/com.microsoft.azure/spark-cdm-connector
The Maven release may be 24-36 hours behind the GitHub release, so check to confirm which is the latest version available on Maven

# Release notes and updates to content
For release notes: see [here](https://github.com/Azure/spark-cdm-connector/releases)

Content updates:
  - [Python sample](https://github.com/Azure/spark-cdm-connector/blob/master/samples/SparkCDMsamplePython.ipynb).  Added a Python version of the original Scala sample

  - [Using the Spark CDM Connector](https://github.com/Azure/spark-cdm-connector/blob/master/documentation/overview.md) guide updated and now in markdown format 
  
  - [Scala sample](https://github.com/Azure/spark-cdm-connector/blob/master/samples/SparkCDMsample.scala).  Original sample showing several use cases
